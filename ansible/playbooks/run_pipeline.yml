- name: Distribute and Run Data Analysis Pipeline via Celery
  hosts: host
  become: yes
  vars:
    datasets:
      - organism: "human"
        data_input_dir: "/mnt/datasets/human_proteome/"
        results_dir: "/mnt/results/human/"
      - organism: "ecoli"
        data_input_dir: "/mnt/datasets/ecoli_proteome/"
        results_dir: "/mnt/results/ecoli/"
  tasks:
    - name: Find all .pdb files for each dataset
      find:
        paths: "{{ item.data_input_dir }}"
        patterns: "*.pdb"
      register: pdb_files
      loop: "{{ datasets }}"
      loop_control:
        label: "{{ item.organism }}"

    - name: Set fact for datasets and their PDB files
      set_fact:
        datasets_pdb: "{{ datasets_pdb | default([]) + [ {
          'organism': item.item.organism,
          'results_dir': item.item.results_dir,
          'data_input_dir': item.item.data_input_dir,
          'files': item.files | default([]) | map(attribute='path') | list
        } ] }}"
      loop: "{{ pdb_files.results }}"
      loop_control:
        label: "{{ item.item.organism }}"
      register: set_fact_result
      until: set_fact_result is succeeded
      retries: 5
      delay: 10


    - name: Enqueue pipeline tasks for each dataset
      debug:
        msg: "Dispatching tasks for organism: {{ item.organism }}"
      loop: "{{ datasets_pdb }}"
      loop_control:
        label: "{{ item.organism }}"