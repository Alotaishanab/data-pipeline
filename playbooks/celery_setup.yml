# /home/almalinux/ansible/playbooks/setup_celery_workers.yml

- name: Setup Celery Workers and Host
  hosts: workers, host
  become: yes
  vars:
    redis_host: "{{ hostvars['storage']['ansible_host'] }}"
    celery_user: "almalinux"
    celery_group: "almalinux"
    celery_bin: "/usr/local/bin/celery"  # Update the path based on where celery is installed
  tasks:
    - name: Install Python3 and pip
      yum:
        name:
          - python3
          - python3-pip
        state: present

    - name: Install Celery and Redis Python packages
      pip:
        name:
          - celery
          - redis
        state: present

    - name: Create data pipeline directory
      file:
        path: /opt/data_pipeline/
        state: directory
        owner: "{{ celery_user }}"
        group: "{{ celery_group }}"
        mode: '0755'

    - name: Deploy Celery Worker Script
      copy:
        dest: /opt/data_pipeline/celery_worker.py
        owner: "{{ celery_user }}"
        group: "{{ celery_group }}"
        mode: '0755'
        content: |
          from celery import Celery
          import subprocess
          import os

          # Define the Redis broker URL using Ansible variable
          app = Celery('tasks', broker='redis://{{ redis_host }}:6379/0')  

          @app.task
          def run_pipeline(pdb_file, results_dir):
              pipeline_script = "/opt/data_pipeline/pipeline_script.py"
              cmd = f"python3 {pipeline_script} {pdb_file} {results_dir}"
              process = subprocess.run(cmd, shell=True, capture_output=True, text=True)
              return {
                  'stdout': process.stdout,
                  'stderr': process.stderr,
                  'returncode': process.returncode
              }

    - name: Deploy Celery Service File
      copy:
        dest: /etc/systemd/system/celery.service
        owner: root
        group: root
        mode: '0644'
        content: |
          [Unit]
          Description=Celery Service
          After=network.target

          [Service]
          Type=simple
          User={{ celery_user }}
          Group={{ celery_group }}
          WorkingDirectory=/opt/data_pipeline/
          ExecStart={{ celery_bin }} -A celery_worker worker --loglevel=info
          Restart=always

          [Install]
          WantedBy=multi-user.target
        force: yes



    - name: Deploy Dispatch Tasks Script
      copy:
        dest: /opt/data_pipeline/dispatch_tasks.py
        owner: "{{ celery_user }}"
        group: "{{ celery_group }}"
        mode: '0755'
        content: |
          import sys
          from celery import Celery

          # Initialize Celery app with the Redis broker
          app = Celery('tasks', broker='redis://{{ redis_host }}:6379/0')

          if __name__ == "__main__":
              if len(sys.argv) != 3:
                  print("Usage: python3 dispatch_tasks.py [INPUT FILE] [OUTPUT DIRECTORY]")
                  sys.exit(1)

              pdb_file = sys.argv[1]
              results_dir = sys.argv[2]
              result = app.send_task('celery_worker.run_pipeline', args=[pdb_file, results_dir])
              print(f"Task {result.id} dispatched for {pdb_file}")



    - name: Reload systemd daemon
      systemd:
        daemon_reload: yes

    - name: Start and enable Celery service
      systemd:
        name: celery
        state: started
        enabled: yes

    - name: Ensure Celery worker script is executable
      file:
        path: /opt/data_pipeline/celery_worker.py
        mode: '0755'
